{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f40d852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to /home/mcb/nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import nltk\n",
    "nltk.download('cmudict')\n",
    "from datetime import datetime\n",
    "formatted_date=datetime.today().strftime(\"%m%d%y\")\n",
    "base_directory = \"probabilities.csv\"\n",
    "data=pd.read_csv(base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba9fd928",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_words</th>\n",
       "      <th>frequency_tasa</th>\n",
       "      <th>frequency_tidy</th>\n",
       "      <th>combined_frequency</th>\n",
       "      <th>average_per_million</th>\n",
       "      <th>sampling_probability_per_million</th>\n",
       "      <th>sampling_probability</th>\n",
       "      <th>estimated_frequency_new_data</th>\n",
       "      <th>rounded_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>64863.0</td>\n",
       "      <td>5373.0</td>\n",
       "      <td>70236.0</td>\n",
       "      <td>27710.444087</td>\n",
       "      <td>2.771044e-02</td>\n",
       "      <td>2.771044e-02</td>\n",
       "      <td>13855.222043</td>\n",
       "      <td>13856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaron</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.550800</td>\n",
       "      <td>3.550800e-06</td>\n",
       "      <td>3.550800e-06</td>\n",
       "      <td>1.775400</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ab</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandon</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.394533</td>\n",
       "      <td>3.945333e-07</td>\n",
       "      <td>3.945333e-07</td>\n",
       "      <td>0.197267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.972667</td>\n",
       "      <td>1.972667e-06</td>\n",
       "      <td>1.972667e-06</td>\n",
       "      <td>0.986333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18767</th>\n",
       "      <td>zoom</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>13.019600</td>\n",
       "      <td>1.301960e-05</td>\n",
       "      <td>1.301960e-05</td>\n",
       "      <td>6.509800</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18768</th>\n",
       "      <td>zoos</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.183600</td>\n",
       "      <td>1.183600e-06</td>\n",
       "      <td>1.183600e-06</td>\n",
       "      <td>0.591800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18769</th>\n",
       "      <td>zucchini</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.183600</td>\n",
       "      <td>1.183600e-06</td>\n",
       "      <td>1.183600e-06</td>\n",
       "      <td>0.591800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18770</th>\n",
       "      <td>zuni</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.183600</td>\n",
       "      <td>1.183600e-06</td>\n",
       "      <td>1.183600e-06</td>\n",
       "      <td>0.591800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18771</th>\n",
       "      <td>zygote</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18772 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_words  frequency_tasa  frequency_tidy  combined_frequency  \\\n",
       "0                a         64863.0          5373.0             70236.0   \n",
       "1            aaron             9.0             0.0                 9.0   \n",
       "2               ab             0.0             0.0                 0.0   \n",
       "3          abandon             0.0             1.0                 1.0   \n",
       "4        abandoned             5.0             0.0                 5.0   \n",
       "...            ...             ...             ...                 ...   \n",
       "18767         zoom            20.0            13.0                33.0   \n",
       "18768         zoos             3.0             0.0                 3.0   \n",
       "18769     zucchini             3.0             0.0                 3.0   \n",
       "18770         zuni             3.0             0.0                 3.0   \n",
       "18771       zygote             0.0             0.0                 0.0   \n",
       "\n",
       "       average_per_million  sampling_probability_per_million  \\\n",
       "0             27710.444087                      2.771044e-02   \n",
       "1                 3.550800                      3.550800e-06   \n",
       "2                 0.000000                      0.000000e+00   \n",
       "3                 0.394533                      3.945333e-07   \n",
       "4                 1.972667                      1.972667e-06   \n",
       "...                    ...                               ...   \n",
       "18767            13.019600                      1.301960e-05   \n",
       "18768             1.183600                      1.183600e-06   \n",
       "18769             1.183600                      1.183600e-06   \n",
       "18770             1.183600                      1.183600e-06   \n",
       "18771             0.000000                      0.000000e+00   \n",
       "\n",
       "       sampling_probability  estimated_frequency_new_data  rounded_frequency  \n",
       "0              2.771044e-02                  13855.222043              13856  \n",
       "1              3.550800e-06                      1.775400                  2  \n",
       "2              0.000000e+00                      0.000000                  0  \n",
       "3              3.945333e-07                      0.197267                  1  \n",
       "4              1.972667e-06                      0.986333                  1  \n",
       "...                     ...                           ...                ...  \n",
       "18767          1.301960e-05                      6.509800                  7  \n",
       "18768          1.183600e-06                      0.591800                  1  \n",
       "18769          1.183600e-06                      0.591800                  1  \n",
       "18770          1.183600e-06                      0.591800                  1  \n",
       "18771          0.000000e+00                      0.000000                  0  \n",
       "\n",
       "[18772 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_number_rows=500000\n",
    "total_sampling_prob = data['sampling_probability'].sum()\n",
    "data['estimated_frequency_new_data'] = (data['sampling_probability']) * (max_number_rows / total_sampling_prob)\n",
    "data['rounded_frequency'] = data['estimated_frequency_new_data'].apply(math.ceil)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35a84a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmu_words = nltk.corpus.cmudict.dict()\n",
    "def is_in_cmu_dict(word):\n",
    "    return word.lower() in cmu_words\n",
    "\n",
    "# Function to generate word\n",
    "def generate_word(words,probs):\n",
    "    word=random.choices(words,weights=probs)\n",
    "    return str(word[0])\n",
    "def create_file(filename, rows , words,probab):\n",
    "    file_name=filename\n",
    "    rows=rows\n",
    "    words=words\n",
    "    probs=probab\n",
    "    scaling_factor= rows/len(words)\n",
    "    remainder = rows - math.floor(scaling_factor)\n",
    "    with open(file_name, 'w') as file:\n",
    "        for i in range(math.floor(scaling_factor)):\n",
    "            word = generate_word(words,probs)\n",
    "            while not is_in_cmu_dict(word):\n",
    "                word = generate_word(words,probs)\n",
    "            file.write((word) + '\\n')\n",
    "        for r in range(remainder):\n",
    "            word_r=generate_word(words,probs)\n",
    "            while not is_in_cmu_dict(word_r):\n",
    "                word_r = generate_word(words,probs)\n",
    "            file.write((word_r) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c00c96f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10K\n",
    "rows=10000\n",
    "file_name='kidwords_'+str(rows)+'_'+formatted_date+'.csv'\n",
    "words=data['unique_words']\n",
    "probabilities=data['sampling_probability']\n",
    "create_file(file_name,rows,words,probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#50K\n",
    "rows=50000\n",
    "file_name='kidwords_'+str(rows)+'_'+formatted_date+'.csv'\n",
    "words=data['unique_words']\n",
    "probabilities=data['sampling_probability']\n",
    "create_file(file_name,rows,words,probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1M\n",
    "rows=100000\n",
    "file_name='kidwords_'+str(rows)+'_'+formatted_date+'.csv'\n",
    "words=data['unique_words']\n",
    "probabilities=data['sampling_probability']\n",
    "create_file(file_name,rows,words,probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2M\n",
    "rows=2000000\n",
    "file_name='kidwords_'+str(rows)+'_'+formatted_date+'.csv'\n",
    "words=data['unique_words']\n",
    "probabilities=data['sampling_probability']\n",
    "create_file(file_name,rows,words,probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5M\n",
    "rows=5000000\n",
    "file_name='kidwords_'+str(rows)+'_'+formatted_date+'.csv'\n",
    "words=data['unique_words']\n",
    "probabilities=data['sampling_probability']\n",
    "create_file(file_name,rows,words,probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5K\n",
    "rows=5000\n",
    "file_name='kidwords_'+str(rows)+'_'+formatted_date+'.csv'\n",
    "words=data['unique_words']\n",
    "probabilities=data['sampling_probability']\n",
    "create_file(file_name,rows,words,probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
