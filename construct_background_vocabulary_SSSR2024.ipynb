{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This script generates the background vocabulary for our pilot simulations, which will be shared at SSSR in Copenhagen in July 2024. To do this we first read-in the My Sidewalks data, count how many total words are present there and then sample from other relevant language sources to generate the background vocabularies for training. This script also generates the test sets for this training condition. See each section below for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "cmuduct = nltk.corpus.cmudict.dict()\n",
    "random.seed(765)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73283/3585101390.py:2: DtypeWarning: Columns (7,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  acbc = pd.read_csv('data/vocabulary/tidycorpus.csv')['token'].to_list()\n"
     ]
    }
   ],
   "source": [
    "cmu = [word.lower() for word in cmuduct.keys() if word.isalpha()]\n",
    "acbc = pd.read_csv('data/vocabulary/tidycorpus.csv')['token'].to_list()\n",
    "\n",
    "acbc = [word.lower() for word in acbc if not isinstance(word, float)]\n",
    "acbc = [word.lower() for word in acbc if word.isalpha()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs = pd.read_csv('data/combined_programs.csv')\n",
    "my_sidewalks = []\n",
    "trade_books = []\n",
    "\n",
    "for i, row in programs.iterrows():\n",
    "    if \"Sidewalks\" in row['program_name']:\n",
    "        if isinstance(row.word_raw, str):\n",
    "            my_sidewalks.append(row.word_raw.lower())\n",
    "    if \"LLI\" in row[\"program_name\"]:\n",
    "        if isinstance(row.word_raw, str):\n",
    "            trade_books.append(row.word_raw.lower())\n",
    "            \n",
    "            \n",
    "my_sidewalks = [word for word in my_sidewalks if word in cmu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_books = [word.lower() for word in trade_books if isinstance(word, str) & word.isalpha()]\n",
    "trade_books = [word for word in trade_books if word in cmu]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Sidewalks has this many total words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10473\n"
     ]
    }
   ],
   "source": [
    "N = len(my_sidewalks)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this many unique words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1282\n"
     ]
    }
   ],
   "source": [
    "print(len(set(my_sidewalks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of constructing the background vocabulary is to identify additional sets of (total) words (i.e., tokens, not types) that comprise a certain proportion of the overall training environment. We will implement this such that we have conditions where the program words represent 25%, 50%, 75%, and 100% of the overall training environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_details = []\n",
    "\n",
    "for i, row in programs.iterrows():\n",
    "    if \"Sidewalks\" in row['program_name']:\n",
    "        program_details.append(row.program_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'My Sidewalks K',\n",
       " 'My Sidewalks Level A Unit 1',\n",
       " 'My Sidewalks Level A Unit 2',\n",
       " 'My Sidewalks Level A Unit 3',\n",
       " 'My Sidewalks Level A Unit 4',\n",
       " 'My Sidewalks Level A Unit 5'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(program_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set the overall vocabulary size to be approximately 10K total words (the exact value will be set by reading all the My Sidewalks books one time; 10,651 total words). This is a realistic and tractable number of words to use as training examples. For the condition where the decodable texts are 100% of the training set, then the My Sidewalks books will all be read once through. In the case where the decodable texts represent 75% of the overall vocabulary, 25% of the words will be sampled from children's sources. Likewise for the 50% and 25% conditions.\n",
    "\n",
    "For each level of `proportion` we will take 20 random draws for the background vocabulary. This will allow us to look at 20 different models for each proportion in each condition. Important here is that for a given draw of background vocabulary for a particular proportion, that draw will be used for both the My Sidewalks (decodable) and trade books model. For example, for sample #1 of background vocabulary of 25% (where 75% of the words are from the program and 25% are from the background) the same set of 25% will be used for both the decodable and trade book models. Then, sample #2 will be a different draw of the 25% of words making up the background vocabulary, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data for our two primary conditions: my_sidewalks (decodable) and trade_books (LLI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each proportion will be associated with a dictionary within which a sample of that proportion will be allocated. The key will be the sample ID and the value will be the sample of words of a given proportion. We will then use these to concatenate to the program samples before writing to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_n = 20\n",
    "\n",
    "background_75 = {}\n",
    "background_50 = {}\n",
    "background_25 = {}\n",
    "background_100 = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programs 100% Background 0%\n",
    "We have a focal condition (\"my sidewalks\"/ decodable) and a comparison condition (\"trade books\"). The comparison condition will be based on the LLI books (we think of them as \"trade books\" for our purposes). We will draw enough texts comprising 10,476 words (i.e., the number of total words in My Sidewalks).\n",
    "\n",
    "The My Sidewalks set is the 100% set for that program, so we don't have to sample it. Below is the sample of LLI books for this proportion. Remember that for these, we don't have resamples because it is a proportion of 1. (though at some point we could look at resamples of the LLI books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = 1\n",
    "treatment_n = round(proportion*N)\n",
    "background_n = N-treatment_n\n",
    "assert treatment_n + background_n == N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_points = [random.choice(range(len(trade_books) - N)) for i in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_books_100 = {}\n",
    "\n",
    "for i in range(20):\n",
    "    ending_point = starting_points[i] + treatment_n\n",
    "    trade_books_100[i] = trade_books[starting_points[i]:ending_point]\n",
    "    assert len(trade_books_100[i]) == N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"data/SSSR2024/program_100_background_0/\"\n",
    "\n",
    "# my_sidewalks only has one draw in this condition because it is all of that program\n",
    "outfile_my_sidewalks = OUTDIR + \"my_sidewalks/\" + \"my_sidewalks_100_background_0\" + \".csv\"\n",
    "with open(outfile_my_sidewalks, \"w\") as f:\n",
    "    for word in my_sidewalks:\n",
    "        f.write(\"{}\\n\".format(word))\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    outfile_trade_books = OUTDIR + \"trade_books/\" + str(i) + \"/trade_books_100_background_0_\" + \"sample_\" + str(i) + \".csv\"\n",
    "    with open(outfile_trade_books, \"w\") as f:\n",
    "        for word in trade_books_100[i]:\n",
    "            f.write(\"{}\\n\".format(word))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programs 75% Background 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = .75\n",
    "treatment_n = round(proportion*N)\n",
    "background_n = N-treatment_n\n",
    "\n",
    "train_my_sidewalks = my_sidewalks[:treatment_n]\n",
    "train_trade_books = trade_books[:treatment_n]\n",
    "\n",
    "\n",
    "for i in range(samples_n):\n",
    "    background_25[i] = [random.choice(acbc) for e in range(background_n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"data/SSSR2024/program_75_background_25/\"\n",
    "\n",
    "for i in background_25.keys():\n",
    "    outfile_my_sidewalks = OUTDIR + \"my_sidewalks/\" + str(i) + \"/my_sidewalks_75_background_25_\" + \"sample_\" + str(i) + \".csv\"\n",
    "    with open(outfile_my_sidewalks, \"w\") as f:\n",
    "        for word in train_my_sidewalks + background_25[i]:\n",
    "            f.write(\"{}\\n\".format(word))\n",
    "    outfile_trade_books = OUTDIR + \"trade_books/\" + str(i) + \"/trade_books_75_background_25_\" + \"sample_\" + str(i) + \".csv\"\n",
    "    with open(outfile_trade_books, \"w\") as f:\n",
    "        for word in train_trade_books + background_25[i]:\n",
    "            f.write(\"{}\\n\".format(word))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programs 50% Background 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = .50\n",
    "treatment_n = round(proportion*N)\n",
    "background_n = N-treatment_n\n",
    "\n",
    "train_my_sidewalks = my_sidewalks[:treatment_n]\n",
    "train_trade_books = trade_books[:treatment_n]\n",
    "\n",
    "for i in range(samples_n):\n",
    "    background_50[i] = [random.choice(acbc) for e in range(background_n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"data/SSSR2024/program_50_background_50/\"\n",
    "\n",
    "for i in background_50.keys():\n",
    "    outfile_my_sidewalks = OUTDIR + \"my_sidewalks/\" + str(i) + \"/my_sidewalks_50_background_50_\" + \"sample_\" + str(i) + \".csv\"\n",
    "    with open(outfile_my_sidewalks, \"w\") as f:\n",
    "        for word in train_my_sidewalks + background_50[i]:\n",
    "            f.write(\"{}\\n\".format(word))\n",
    "    outfile_trade_books = OUTDIR + \"trade_books/\" + str(i) + \"/trade_books_50_background_50_\" + \"sample_\" + str(i) + \".csv\"\n",
    "    with open(outfile_trade_books, \"w\") as f:\n",
    "        for word in train_trade_books + background_50[i]:\n",
    "            f.write(\"{}\\n\".format(word))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program 25% Background 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = .25\n",
    "treatment_n = round(proportion*N)\n",
    "background_n = N-treatment_n\n",
    "\n",
    "train_my_sidewalks = my_sidewalks[:treatment_n]\n",
    "train_trade_books = trade_books[:treatment_n]\n",
    "\n",
    "for i in range(samples_n):\n",
    "    background_75[i] = [random.choice(acbc) for e in range(background_n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"data/SSSR2024/program_25_background_75/\"\n",
    "\n",
    "for i in background_75.keys():\n",
    "    outfile_my_sidewalks = OUTDIR + \"my_sidewalks/\" + str(i) + \"/my_sidewalks_25_background_75_\" + \"sample_\" + str(i) + \".csv\"\n",
    "    with open(outfile_my_sidewalks, \"w\") as f:\n",
    "        for word in train_my_sidewalks + background_75[i]:\n",
    "            f.write(\"{}\\n\".format(word))\n",
    "    outfile_trade_books = OUTDIR + \"trade_books/\" + str(i) + \"/trade_books_25_background_75_\" + \"sample_\" + str(i) + \".csv\"\n",
    "    with open(outfile_trade_books, \"w\") as f:\n",
    "        for word in train_trade_books + background_75[i]:\n",
    "            f.write(\"{}\\n\".format(word))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program 0% Background 100%\n",
    "This is a set of children's words for basic comparison. We will have 20 samples of words drawn randomly from ACBC for a comparison for all models too. We have similar samples from the LLI/ trade books group above, but this is the condition where all words are from the background vocabulary. We only have one set for this purpose because we want to compare each program against a single sample of background vocabulary (in 20 different samples). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = 0\n",
    "treatment_n = round(proportion*N)\n",
    "background_n = N-treatment_n\n",
    "\n",
    "train_my_sidewalks = my_sidewalks[:treatment_n]\n",
    "train_trade_books = trade_books[:treatment_n]\n",
    "\n",
    "for i in range(samples_n):\n",
    "    background_100[i] = [random.choice(acbc) for e in range(background_n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"data/SSSR2024/program_0_background_100/\"\n",
    "\n",
    "for i in background_100.keys():\n",
    "    outfile = OUTDIR + str(i) + \"/my_sidewalks_0_background_100_\" + \"sample_\" + str(i) + \".csv\"\n",
    "    with open(outfile, \"w\") as f:\n",
    "        for word in background_100[i]:\n",
    "            f.write(\"{}\\n\".format(word))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
