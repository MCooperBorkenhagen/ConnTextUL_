{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This script generates the background vocabulary for our pilot simulations, which will be shared at SSSR in Copenhagen in July 2024. To do this we first read-in the My Sidewalks data, count how many total words are present there and then sample from other relevant language sources to generate the background vocabularies for training. This script also generates the test sets for this training condition. See each section below for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "random.seed(765)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "programs = pd.read_csv('data/combined_programs.csv')\n",
    "my_sidewalks = []\n",
    "trade_books = []\n",
    "\n",
    "for i, row in programs.iterrows():\n",
    "    if \"Sidewalks\" in row['program_name']:\n",
    "        if isinstance(row.word_raw, str):\n",
    "            my_sidewalks.append(row.word_raw.lower())\n",
    "    if \"LLI\" in row[\"program_name\"]:\n",
    "        if isinstance(row.word_raw, str):\n",
    "            trade_books.append(row.word_raw.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in ACBC words, CMU words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: EOF inside string starting at row 69909",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15855/673430780.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0macbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/vocabulary/tidycorpus.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0macbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0macbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/cmu_words.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/python38_env/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python38_env/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python38_env/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python38_env/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python38_env/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python38_env/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python38_env/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python38_env/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/python38_env/lib/python3.8/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 69909"
     ]
    }
   ],
   "source": [
    "acbc = pd.read_csv('data/vocabulary/tidycorpus.csv')\n",
    "acbc = [word.lower() for word in acbc.token.tolist() if isinstance(word, str) & word.isalpha()]\n",
    "import csv\n",
    "\n",
    "with open('data/cmu_words.csv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter=\",\")\n",
    "    for row in reader:\n",
    "        cmu.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Sidewalks has this many total words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10654\n"
     ]
    }
   ],
   "source": [
    "N = len(my_sidewalks)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this many unique words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1351\n"
     ]
    }
   ],
   "source": [
    "print(len(set(my_sidewalks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of constructing the background vocabulary is to identify additional sets of (total) words (i.e., tokens, not types) that comprise a certain proportion of the overall training environment. We will implement this such that we have conditions where the program words represent 25%, 50%, 75%, and 100% of the overall training environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_details = []\n",
    "\n",
    "for i, row in programs.iterrows():\n",
    "    if \"Sidewalks\" in row['program_name']:\n",
    "        program_details.append(row.program_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'My Sidewalks K',\n",
       " 'My Sidewalks Level A Unit 1',\n",
       " 'My Sidewalks Level A Unit 2',\n",
       " 'My Sidewalks Level A Unit 3',\n",
       " 'My Sidewalks Level A Unit 4',\n",
       " 'My Sidewalks Level A Unit 5'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(program_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set the overall vocabulary size to be approximately 10K total words (the exact value will be set by reading all the My Sidewalks books one time; 10,651 total words). This is a realistic and tractable number of words to use as training examples. For the condition where the decodable texts are 100% of the training set, then the My Sidewalks books will all be read once through. In the case where the decodable texts represent 75% of the overall vocabulary, 25% of the words will be sampled from children's sources. Likewise for the 50% and 25% conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My Sidewalks 100% condition..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diz',\n",
       " 'i',\n",
       " 'am',\n",
       " 'diz',\n",
       " 'i',\n",
       " 'am',\n",
       " 'nat',\n",
       " 'nat',\n",
       " 'can',\n",
       " 'hop',\n",
       " 'diz',\n",
       " 'can',\n",
       " 'not',\n",
       " 'hop',\n",
       " 'diz',\n",
       " 'can',\n",
       " 'hop',\n",
       " 'can',\n",
       " 'diz',\n",
       " 'hit',\n",
       " 'it',\n",
       " 'i',\n",
       " 'am',\n",
       " 'diz',\n",
       " 'can',\n",
       " 'i',\n",
       " 'hit',\n",
       " 'it',\n",
       " 'yes',\n",
       " 'i',\n",
       " 'can',\n",
       " 'hit',\n",
       " 'it',\n",
       " 'i',\n",
       " 'can',\n",
       " 'run',\n",
       " 'i',\n",
       " 'can',\n",
       " 'run',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sun',\n",
       " 'yes',\n",
       " 'i',\n",
       " 'can',\n",
       " 'win',\n",
       " 'it',\n",
       " 'was',\n",
       " 'hot',\n",
       " 'the',\n",
       " 'sun',\n",
       " 'was',\n",
       " 'hot',\n",
       " 'diz',\n",
       " 'was',\n",
       " 'hot',\n",
       " 'diz',\n",
       " 'got',\n",
       " 'in',\n",
       " 'he',\n",
       " 'got',\n",
       " 'wet',\n",
       " 'a',\n",
       " 'bug',\n",
       " 'got',\n",
       " 'in',\n",
       " 'the',\n",
       " 'bug',\n",
       " 'got',\n",
       " 'wet',\n",
       " 'it',\n",
       " 'was',\n",
       " 'fun',\n",
       " 'dan',\n",
       " 'and',\n",
       " 'the',\n",
       " 'van',\n",
       " 'dan',\n",
       " 'can',\n",
       " 'hop',\n",
       " 'in',\n",
       " 'the',\n",
       " 'big',\n",
       " 'red',\n",
       " 'van',\n",
       " 'was',\n",
       " 'tim',\n",
       " 'in',\n",
       " 'the',\n",
       " 'red',\n",
       " 'van',\n",
       " 'yes',\n",
       " 'he',\n",
       " 'was',\n",
       " 'in',\n",
       " 'the',\n",
       " 'big',\n",
       " 'red',\n",
       " 'van',\n",
       " 'bud',\n",
       " 'the',\n",
       " 'pup',\n",
       " 'diz',\n",
       " 'had',\n",
       " 'a',\n",
       " 'pet',\n",
       " 'pup',\n",
       " 'the',\n",
       " 'pup',\n",
       " 'was',\n",
       " 'bud',\n",
       " 'he',\n",
       " 'fed',\n",
       " 'him',\n",
       " 'diz',\n",
       " 'hid',\n",
       " 'in',\n",
       " 'a',\n",
       " 'box',\n",
       " 'with',\n",
       " 'bud',\n",
       " 'the',\n",
       " 'pup',\n",
       " 'diz',\n",
       " 'said',\n",
       " 'run',\n",
       " 'bud',\n",
       " 'he',\n",
       " 'ran',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sun',\n",
       " 'with',\n",
       " 'bud',\n",
       " 'the',\n",
       " 'pup',\n",
       " 'mom',\n",
       " 'said',\n",
       " 'diz',\n",
       " 'bud',\n",
       " 'he',\n",
       " 'was',\n",
       " 'with',\n",
       " 'bud',\n",
       " 'the',\n",
       " 'pup',\n",
       " 'a',\n",
       " 'nut',\n",
       " 'in',\n",
       " 'a',\n",
       " 'cup',\n",
       " 'a',\n",
       " 'pup',\n",
       " 'dug',\n",
       " 'in',\n",
       " 'the',\n",
       " 'mud',\n",
       " 'the',\n",
       " 'pup',\n",
       " 'dug',\n",
       " 'up',\n",
       " 'a',\n",
       " 'nut',\n",
       " 'pop',\n",
       " 'the',\n",
       " 'nut',\n",
       " 'hit',\n",
       " 'a',\n",
       " 'log',\n",
       " 'diz',\n",
       " 'sat',\n",
       " 'on',\n",
       " 'the',\n",
       " 'log',\n",
       " 'the',\n",
       " 'nut',\n",
       " 'went',\n",
       " 'up',\n",
       " 'pop',\n",
       " 'the',\n",
       " 'nut',\n",
       " 'hit',\n",
       " 'the',\n",
       " 'cup',\n",
       " 'a',\n",
       " 'nut',\n",
       " 'was',\n",
       " 'in',\n",
       " 'the',\n",
       " 'cup',\n",
       " 'tag',\n",
       " 'is',\n",
       " 'fun',\n",
       " 'tap',\n",
       " 'diz',\n",
       " 'is',\n",
       " 'it',\n",
       " 'can',\n",
       " 'diz',\n",
       " 'tag',\n",
       " 'max',\n",
       " 'diz',\n",
       " 'can',\n",
       " 'not',\n",
       " 'tag',\n",
       " 'max',\n",
       " 'tap',\n",
       " 'ron',\n",
       " 'is',\n",
       " 'it',\n",
       " 'can',\n",
       " 'ron',\n",
       " 'tag',\n",
       " 'diz',\n",
       " 'ron',\n",
       " 'is',\n",
       " 'not',\n",
       " 'fast',\n",
       " 'he',\n",
       " 'can',\n",
       " 'not',\n",
       " 'tag',\n",
       " 'diz',\n",
       " 'tap',\n",
       " 'pam',\n",
       " 'is',\n",
       " 'it',\n",
       " 'can',\n",
       " 'pam',\n",
       " 'tag',\n",
       " 'ron',\n",
       " 'yes',\n",
       " 'pam',\n",
       " 'can',\n",
       " 'tag',\n",
       " 'ron',\n",
       " 'tag',\n",
       " 'is',\n",
       " 'fun',\n",
       " 'ham',\n",
       " 'with',\n",
       " 'jam',\n",
       " 'diz',\n",
       " 'and',\n",
       " 'rex',\n",
       " 'set',\n",
       " 'up',\n",
       " 'a',\n",
       " 'box',\n",
       " 'diz',\n",
       " 'got',\n",
       " 'a',\n",
       " 'bun',\n",
       " 'and',\n",
       " 'jam',\n",
       " 'rex',\n",
       " 'got',\n",
       " 'a',\n",
       " 'bun',\n",
       " 'and',\n",
       " 'ham',\n",
       " 'get',\n",
       " 'a',\n",
       " 'bun',\n",
       " 'with',\n",
       " 'jam',\n",
       " 'get',\n",
       " 'jam',\n",
       " 'on',\n",
       " 'a',\n",
       " 'bun',\n",
       " 'get',\n",
       " 'a',\n",
       " 'bun',\n",
       " 'with',\n",
       " 'ham',\n",
       " 'get',\n",
       " 'ham',\n",
       " 'on',\n",
       " 'a',\n",
       " 'bun',\n",
       " 'jan',\n",
       " 'and',\n",
       " 'nat',\n",
       " 'had',\n",
       " 'a',\n",
       " 'bun',\n",
       " 'with',\n",
       " 'jam',\n",
       " 'yum',\n",
       " 'ted',\n",
       " 'and',\n",
       " 'ben',\n",
       " 'had',\n",
       " 'ham',\n",
       " 'on',\n",
       " 'a',\n",
       " 'bun',\n",
       " 'yum',\n",
       " 'diz',\n",
       " 'and',\n",
       " 'rex',\n",
       " 'had',\n",
       " 'ham',\n",
       " 'with',\n",
       " 'jam',\n",
       " 'yum',\n",
       " 'a',\n",
       " 'net',\n",
       " 'a',\n",
       " 'cup',\n",
       " 'and',\n",
       " 'a',\n",
       " 'bug',\n",
       " 'diz',\n",
       " 'and',\n",
       " 'sam',\n",
       " 'sat',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sand',\n",
       " 'sam',\n",
       " 'had',\n",
       " 'a',\n",
       " 'net',\n",
       " 'diz',\n",
       " 'had',\n",
       " 'a',\n",
       " 'big',\n",
       " 'cup',\n",
       " 'with',\n",
       " 'a',\n",
       " 'lid',\n",
       " 'sam',\n",
       " 'said',\n",
       " 'to',\n",
       " 'get',\n",
       " 'up',\n",
       " 'fast',\n",
       " 'a',\n",
       " 'bug',\n",
       " 'was',\n",
       " 'on',\n",
       " 'diz',\n",
       " 'a',\n",
       " 'big',\n",
       " 'bug',\n",
       " 'was',\n",
       " 'on',\n",
       " 'top',\n",
       " 'of',\n",
       " 'diz',\n",
       " 'will',\n",
       " 'diz',\n",
       " 'get',\n",
       " 'the',\n",
       " 'bug',\n",
       " 'with',\n",
       " 'the',\n",
       " 'cup',\n",
       " 'will',\n",
       " 'sam',\n",
       " 'get',\n",
       " 'the',\n",
       " 'bug',\n",
       " 'with',\n",
       " 'the',\n",
       " 'net',\n",
       " 'bam',\n",
       " 'bump',\n",
       " 'bop',\n",
       " 'bump',\n",
       " 'bop',\n",
       " 'diz',\n",
       " 'and',\n",
       " 'sam',\n",
       " 'sat',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sand',\n",
       " 'diz',\n",
       " 'had',\n",
       " 'a',\n",
       " 'net',\n",
       " 'sam',\n",
       " 'had',\n",
       " 'a',\n",
       " 'big',\n",
       " 'cup',\n",
       " 'with',\n",
       " 'a',\n",
       " 'lid',\n",
       " 'tim',\n",
       " 'tim',\n",
       " 'has',\n",
       " 'a',\n",
       " 'nap',\n",
       " 'tim',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'mud',\n",
       " 'a',\n",
       " 'big',\n",
       " 'bug',\n",
       " 'sat',\n",
       " 'on',\n",
       " 'top',\n",
       " 'of',\n",
       " 'tim',\n",
       " 'the',\n",
       " 'bug',\n",
       " 'did',\n",
       " 'tug',\n",
       " 'on',\n",
       " 'tim',\n",
       " 'tim',\n",
       " 'was',\n",
       " 'mad',\n",
       " 'at',\n",
       " 'the',\n",
       " 'bug',\n",
       " 'the',\n",
       " 'bug',\n",
       " 'got',\n",
       " 'him',\n",
       " 'up',\n",
       " 'tim',\n",
       " 'ran',\n",
       " 'to',\n",
       " 'nip',\n",
       " 'the',\n",
       " 'bug',\n",
       " 'the',\n",
       " 'bug',\n",
       " 'was',\n",
       " 'on',\n",
       " 'the',\n",
       " 'big',\n",
       " 'log',\n",
       " 'tim',\n",
       " 'ran',\n",
       " 'to',\n",
       " 'it',\n",
       " 'the',\n",
       " 'bug',\n",
       " 'hid',\n",
       " 'in',\n",
       " 'the',\n",
       " 'log',\n",
       " 'tim',\n",
       " 'got',\n",
       " 'up',\n",
       " 'but',\n",
       " 'tim',\n",
       " 'did',\n",
       " 'not',\n",
       " 'fit',\n",
       " 'in',\n",
       " 'it',\n",
       " 'tim',\n",
       " 'got',\n",
       " 'up',\n",
       " 'on',\n",
       " 'the',\n",
       " 'log',\n",
       " 'the',\n",
       " 'bug',\n",
       " 'was',\n",
       " 'not',\n",
       " 'in',\n",
       " 'the',\n",
       " 'log',\n",
       " 'the',\n",
       " 'log',\n",
       " 'is',\n",
       " 'big',\n",
       " 'but',\n",
       " 'it',\n",
       " 'did',\n",
       " 'tip',\n",
       " 'tim',\n",
       " 'can',\n",
       " 'not',\n",
       " 'sit',\n",
       " 'on',\n",
       " 'it',\n",
       " 'tim',\n",
       " 'can',\n",
       " 'not',\n",
       " 'sit',\n",
       " 'up',\n",
       " 'tag',\n",
       " 'runs',\n",
       " 'up',\n",
       " 'to',\n",
       " 'tim',\n",
       " 'tag',\n",
       " 'can',\n",
       " 'not',\n",
       " 'tip',\n",
       " 'him',\n",
       " 'up',\n",
       " 'the',\n",
       " 'pup',\n",
       " 'runs',\n",
       " 'on',\n",
       " 'it',\n",
       " 'is',\n",
       " 'hot',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sun',\n",
       " 'tim',\n",
       " 'is',\n",
       " 'hot',\n",
       " 'and',\n",
       " 'sad',\n",
       " 'al',\n",
       " 'runs',\n",
       " 'up',\n",
       " 'to',\n",
       " 'tim',\n",
       " 'al',\n",
       " 'is',\n",
       " 'big',\n",
       " 'al',\n",
       " 'can',\n",
       " 'tip',\n",
       " 'him',\n",
       " 'up',\n",
       " 'al',\n",
       " 'has',\n",
       " 'to',\n",
       " 'tug',\n",
       " 'on',\n",
       " 'tim',\n",
       " 'tim',\n",
       " 'got',\n",
       " 'a',\n",
       " 'big',\n",
       " 'tug',\n",
       " 'al',\n",
       " 'got',\n",
       " 'him',\n",
       " 'up',\n",
       " 'tim',\n",
       " 'has',\n",
       " 'a',\n",
       " 'pal',\n",
       " 'his',\n",
       " 'pal',\n",
       " 'is',\n",
       " 'al',\n",
       " 'tim',\n",
       " 'and',\n",
       " 'al',\n",
       " 'run',\n",
       " 'to',\n",
       " 'the',\n",
       " 'mud',\n",
       " 'tim',\n",
       " 'and',\n",
       " 'al',\n",
       " 'sat',\n",
       " 'in',\n",
       " 'the',\n",
       " 'mud',\n",
       " 'tim',\n",
       " 'and',\n",
       " 'al',\n",
       " 'had',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'fun',\n",
       " 'the',\n",
       " 'pup',\n",
       " 'and',\n",
       " 'the',\n",
       " 'bug',\n",
       " 'a',\n",
       " 'big',\n",
       " 'bug',\n",
       " 'sat',\n",
       " 'on',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'a',\n",
       " 'log',\n",
       " 'the',\n",
       " 'pup',\n",
       " 'ran',\n",
       " 'to',\n",
       " 'get',\n",
       " 'the',\n",
       " 'bug',\n",
       " 'the',\n",
       " 'pup',\n",
       " 'fell',\n",
       " 'in',\n",
       " 'the',\n",
       " 'mud',\n",
       " 'the',\n",
       " 'pup',\n",
       " 'got',\n",
       " 'mud',\n",
       " 'on',\n",
       " 'the',\n",
       " 'rug',\n",
       " 'mom',\n",
       " 'said',\n",
       " 'to',\n",
       " 'get',\n",
       " 'the',\n",
       " 'pup',\n",
       " 'in',\n",
       " 'the',\n",
       " 'tub',\n",
       " 'a',\n",
       " 'big',\n",
       " 'bug',\n",
       " 'sat',\n",
       " 'on',\n",
       " 'a',\n",
       " 'cup',\n",
       " 'in',\n",
       " 'the',\n",
       " 'tub',\n",
       " 'the',\n",
       " 'pup',\n",
       " 'got',\n",
       " 'up',\n",
       " 'to',\n",
       " 'get',\n",
       " 'the',\n",
       " 'bug',\n",
       " 'the',\n",
       " 'bug',\n",
       " 'fell',\n",
       " 'in',\n",
       " 'the',\n",
       " 'tub',\n",
       " 'the',\n",
       " 'bug',\n",
       " 'and',\n",
       " 'the',\n",
       " 'pup',\n",
       " 'had',\n",
       " 'fun',\n",
       " 'in',\n",
       " 'the',\n",
       " 'tub',\n",
       " 'mom',\n",
       " 'sent',\n",
       " 'diz',\n",
       " 'to',\n",
       " 'get',\n",
       " 'a',\n",
       " 'mop',\n",
       " 'al',\n",
       " 'al',\n",
       " 'is',\n",
       " 'big',\n",
       " 'al',\n",
       " 'ran',\n",
       " 'and',\n",
       " 'ran',\n",
       " 'dot',\n",
       " 'has',\n",
       " 'a',\n",
       " 'hot',\n",
       " 'dog',\n",
       " 'al',\n",
       " 'hid',\n",
       " 'al',\n",
       " 'ran',\n",
       " 'to',\n",
       " 'dot',\n",
       " 'dot',\n",
       " 'and',\n",
       " 'al',\n",
       " 'had',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'hot',\n",
       " 'dog',\n",
       " 'al',\n",
       " 'is',\n",
       " 'not',\n",
       " 'sad',\n",
       " 'al',\n",
       " 'got',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'hot',\n",
       " 'dog',\n",
       " 'tom',\n",
       " 'has',\n",
       " 'a',\n",
       " 'pop',\n",
       " 'al',\n",
       " 'hid',\n",
       " 'al',\n",
       " 'ran',\n",
       " 'to',\n",
       " 'tom',\n",
       " 'tom',\n",
       " 'ran',\n",
       " 'and',\n",
       " 'ran',\n",
       " 'al',\n",
       " 'was',\n",
       " 'sad',\n",
       " 'the',\n",
       " 'pop',\n",
       " 'was',\n",
       " 'hot',\n",
       " 'the',\n",
       " 'man',\n",
       " 'had',\n",
       " 'a',\n",
       " 'hot',\n",
       " 'dog',\n",
       " 'al',\n",
       " 'hid',\n",
       " 'the',\n",
       " 'man',\n",
       " 'ran',\n",
       " 'al',\n",
       " 'got',\n",
       " 'mad',\n",
       " 'at',\n",
       " 'the',\n",
       " 'man',\n",
       " 'the',\n",
       " 'man',\n",
       " 'had',\n",
       " 'the',\n",
       " 'hot',\n",
       " 'dog',\n",
       " 'the',\n",
       " 'man',\n",
       " 'got',\n",
       " 'on',\n",
       " 'the',\n",
       " 'bus',\n",
       " 'al',\n",
       " 'ran',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bus',\n",
       " 'the',\n",
       " 'man',\n",
       " 'was',\n",
       " 'on',\n",
       " 'the',\n",
       " 'bus',\n",
       " 'al',\n",
       " 'ran',\n",
       " 'and',\n",
       " 'hid',\n",
       " 'al',\n",
       " 'was',\n",
       " 'sad',\n",
       " 'dot',\n",
       " 'and',\n",
       " 'tom',\n",
       " 'ran',\n",
       " 'to',\n",
       " 'al',\n",
       " 'tom',\n",
       " 'was',\n",
       " 'not',\n",
       " 'mad',\n",
       " 'at',\n",
       " 'al',\n",
       " 'dot',\n",
       " 'was',\n",
       " 'not',\n",
       " 'mad',\n",
       " 'at',\n",
       " 'al',\n",
       " 'al',\n",
       " 'was',\n",
       " 'not',\n",
       " 'sad',\n",
       " 'dot',\n",
       " 'got',\n",
       " 'on',\n",
       " 'top',\n",
       " 'of',\n",
       " 'al',\n",
       " 'al',\n",
       " 'ran',\n",
       " 'tom',\n",
       " 'got',\n",
       " 'al',\n",
       " 'a',\n",
       " 'pop',\n",
       " 'dot',\n",
       " 'got',\n",
       " 'him',\n",
       " 'a',\n",
       " 'hot',\n",
       " 'dog',\n",
       " 'al',\n",
       " 'was',\n",
       " 'not',\n",
       " 'sad',\n",
       " 'taking',\n",
       " 'care',\n",
       " 'of',\n",
       " 'pets',\n",
       " 'i',\n",
       " 'like',\n",
       " 'the',\n",
       " 'bird',\n",
       " 'i',\n",
       " 'like',\n",
       " 'the',\n",
       " 'cat',\n",
       " 'i',\n",
       " 'like',\n",
       " 'the',\n",
       " 'fish',\n",
       " 'i',\n",
       " 'like',\n",
       " 'the',\n",
       " 'dog',\n",
       " 'what',\n",
       " 'pets',\n",
       " 'like',\n",
       " 'the',\n",
       " 'fish',\n",
       " 'like',\n",
       " 'the',\n",
       " 'tank',\n",
       " 'the',\n",
       " 'kittens',\n",
       " 'like',\n",
       " 'the',\n",
       " 'mouse',\n",
       " 'the',\n",
       " 'birds',\n",
       " 'like',\n",
       " 'the',\n",
       " 'toy',\n",
       " 'the',\n",
       " 'puppies',\n",
       " 'like',\n",
       " 'the',\n",
       " 'towel',\n",
       " 'people',\n",
       " 'help',\n",
       " 'animals',\n",
       " 'i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'vet',\n",
       " 'i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'firefighter',\n",
       " 'i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'dog',\n",
       " 'walker',\n",
       " 'i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'zookeeper',\n",
       " 'pam',\n",
       " 'and',\n",
       " 'tam',\n",
       " 'tam',\n",
       " 'pam',\n",
       " 'is',\n",
       " 'a',\n",
       " 'vet',\n",
       " 'tam',\n",
       " 'tam',\n",
       " 'is',\n",
       " 'a',\n",
       " 'puppy',\n",
       " 'i',\n",
       " 'look',\n",
       " 'at',\n",
       " 'tam',\n",
       " 'tam',\n",
       " 'i',\n",
       " 'pat',\n",
       " 'tam',\n",
       " 'tam',\n",
       " 'tam',\n",
       " 'tam',\n",
       " 'sat',\n",
       " 'i',\n",
       " 'like',\n",
       " 'tam',\n",
       " 'tam',\n",
       " 'sit',\n",
       " 'sam',\n",
       " 'i',\n",
       " 'am',\n",
       " 'tim',\n",
       " 'sam',\n",
       " 'is',\n",
       " 'a',\n",
       " 'puppy',\n",
       " 'sit',\n",
       " 'sam',\n",
       " 'sit',\n",
       " 'look',\n",
       " 'at',\n",
       " 'sam',\n",
       " 'sit',\n",
       " 'i',\n",
       " 'pat',\n",
       " 'sam',\n",
       " 'pat',\n",
       " 'pat',\n",
       " 'pat',\n",
       " 'sam',\n",
       " 'pats',\n",
       " 'tim',\n",
       " 'animals',\n",
       " 'help',\n",
       " 'people',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'camel',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'cow',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'sheep',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'dog',\n",
       " 'what',\n",
       " 'we',\n",
       " 'like',\n",
       " 'you',\n",
       " 'have',\n",
       " 'a',\n",
       " 'chicken',\n",
       " 'we',\n",
       " 'like',\n",
       " 'the',\n",
       " 'eggs',\n",
       " 'you',\n",
       " 'have',\n",
       " 'bees',\n",
       " 'we',\n",
       " 'like',\n",
       " 'the',\n",
       " 'honey',\n",
       " 'you',\n",
       " 'have',\n",
       " 'a',\n",
       " 'cow',\n",
       " 'we',\n",
       " 'like',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'you',\n",
       " 'have',\n",
       " 'a',\n",
       " 'horse',\n",
       " 'we',\n",
       " 'like',\n",
       " 'you',\n",
       " 'bob',\n",
       " 'and',\n",
       " 'tom',\n",
       " 'i',\n",
       " 'am',\n",
       " 'bob',\n",
       " 'i',\n",
       " 'am',\n",
       " 'tom',\n",
       " 'we',\n",
       " 'have',\n",
       " 'a',\n",
       " 'cab',\n",
       " 'we',\n",
       " 'like',\n",
       " 'the',\n",
       " 'cab',\n",
       " 'we',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sidewalks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control condition\n",
    "The control condition will be based on the LLI books, which represent \"trade books\", roughly. From the LLI books we will draw enough texts comprising 10,654 words (i.e., the number of total words in My Sidewalks). Note that the control condition represents a set of words where the My Sidewalks proportion is 0% of the words - that is, the background vocabulary are selected from these control words to comprise 25%, 50%, 75% of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = []\n",
    "\n",
    "for i in range(N):\n",
    "    sampled = random.choice(acbc)\n",
    "    control.append(sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10654"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condition: 75% of words are from My Sidewalks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = .75\n",
    "treatment_n = round(proportion*N)\n",
    "background_n = N-treatment_n\n",
    "assert treatment_n + background_n == N\n",
    "condition_75 = my_sidewalks[:treatment_n]\n",
    "condition_75.extend([random.choice(acbc) for i in range(background_n)])\n",
    "assert len(condition_75) == N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condition: 50% of words are from My Sidewalks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = .50\n",
    "treatment_n = round(proportion*N)\n",
    "background_n = N-treatment_n\n",
    "assert treatment_n + background_n == N\n",
    "condition_50 = my_sidewalks[:treatment_n]\n",
    "condition_50.extend([random.choice(acbc) for i in range(background_n)])\n",
    "assert len(condition_50) == N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condition: 25% of words are from My Sidewalks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = .25\n",
    "treatment_n = round(proportion*N)\n",
    "background_n = N-treatment_n\n",
    "assert treatment_n + background_n == N\n",
    "condition_25 = my_sidewalks[:treatment_n]\n",
    "condition_25.extend([random.choice(acbc) for i in range(background_n)])\n",
    "assert len(condition_25) == N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condition: Trade Books\n",
    "Just for exploration, let's also include Trade Books, using LLI for that purpose. This can be another training environment. We will length match with My Sidewalks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_books_sample = []\n",
    "for i in range(N):\n",
    "    trade_books_sample.append(random.choice(trade_books))\n",
    "\n",
    "assert len(trade_books_sample) == N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write datasets\n",
    "Let's write these to `data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/my_sidewalks_100_percent.csv', \"w\") as f:\n",
    "    for word in my_sidewalks:\n",
    "        f.write(\"{}\\n\".format(word))\n",
    "        \n",
    "with open('data/my_sidewalks_75_percent_background_25_percent.csv', \"w\") as f:\n",
    "    for word in condition_75:\n",
    "        f.write(\"{}\\n\".format(word))\n",
    "        \n",
    "with open('data/my_sidewalks_50_percent_background_50_percent.csv', \"w\") as f:\n",
    "    for word in condition_50:\n",
    "        f.write(\"{}\\n\".format(word))\n",
    "        \n",
    "with open('data/my_sidewalks_25_percent_background_75_percent.csv', \"w\") as f:\n",
    "    for word in condition_25:\n",
    "        f.write(\"{}\\n\".format(word))\n",
    "        \n",
    "        \n",
    "with open('data/my_sidewalks_0_percent_background_100_percent.csv', \"w\") as f:\n",
    "    for word in control:\n",
    "        f.write(\"{}\\n\".format(word))\n",
    "        \n",
    "with open('data/trade_books_100_percent.csv', \"w\") as f:\n",
    "    for word in trade_books:\n",
    "        f.write(\"{}\\n\".format(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sets\n",
    "For test sets, sets of 10,654 words will be selected from children's and adult language sources. For each a random sample will be drawn and a frequency weighted sample will be drawn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
